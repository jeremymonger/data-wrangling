{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "## Gather\n",
    "\n",
    "First I needed to get my three datasets. An enhanced dataset was given to me, a prediction dataset was acquired through the requests library, and further information was acquired through the twitter API.\n",
    "\n",
    "## Assess\n",
    "\n",
    "### Ratings\n",
    "After loading the data sets, the first thing I began to investigate was the ratings, as there were some suspicious values. However, reading the texts they were pulled from was inefficient in pandas, so I loaded some into spreadsheets to get a better feel for what problems were occurring. I also brought some up on twitter itself. I noticed several problems this way – rating were being grabbed from the first forward slash in a text, even if this was something like a date, or a joke about number of legs. The algorithm also couldn’t handle decimal ratings.\n",
    "\n",
    "### Names\n",
    "The algorithm appeared to have grabbed whatever the next word was in texts that started with “This is __” . These were just regular words, “This is a...” , “This is just...”, etc.  It also failed to grab names with apostrophes. \n",
    "\n",
    "### Retweets\n",
    "These were usually duplicates, or other people’s ratings, etc.\n",
    "\n",
    "### Data types, format\n",
    "While performing my other assessments, I began to grow a list of variables that were not in their optimal data type for analysis.  I also noted that ratings being given as a numerator and denominator was less useful compared to a ratio (though I’m glad they were provided in that format, I would have missed a lot of low quality data otherwise!).\n",
    "\n",
    "### Data spread across multiple data sets, varying data points\n",
    "I knew to get the data tidy, I was going to need to merge my three data sets. And, as they didn’t all include the same data points, I needed to make sure to only grab the ones present in all three.\n",
    "\n",
    "### Outliers\n",
    "This one wasn’t a realized problem until I started trying to explore the data and all my visualizations were failing. Some variables contained extremes that distorted the data.\n",
    "\n",
    "## Cleaning\n",
    "After defining all the problems I found in the Assessing phase, this phase, while time-consuming, was fairly straightforward.   Using my current skills, combined with every coder’s favorite tool, Google, I hacked away at the defined problems until I had a data set I felt I could explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
